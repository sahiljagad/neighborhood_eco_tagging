# -*- coding: utf-8 -*-
"""ecoTagFineTuneModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sBR2jBQ2Cu_piEtDehL9lQn7VpyqRzki
"""

from google.colab import drive
drive.mount('/content/drive')

'!unzip "/content/drive/MyDrive/dataset.zip" -d /content/' #collab command to unzip the dataset

import os
import shutil
from datasets import load_dataset, DatasetDict
from torchvision import transforms
from torchvision.datasets import ImageFolder
from PIL import Image
import matplotlib.pyplot as plt
import random
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from transformers import ViTForImageClassification, ViTFeatureExtractor, ViTConfig
from tqdm import tqdm  # for progress bar
from google.colab import files
import json

if torch.cuda.is_available():
    print("GPU is available:", torch.cuda.get_device_name(0))
else:
    print("No GPU found. Go to Runtime > Change runtime type > select GPU.")

def clean_dataset(root):
    valid_exts = (".jpg", ".jpeg", ".png")
    for class_name in os.listdir(root):
        class_path = os.path.join(root, class_name)
        if not os.path.isdir(class_path):
            print(f"Not a directory: {class_path}")
            continue
        for file in os.listdir(class_path):
            file_path = os.path.join(class_path, file)
            if not file.lower().endswith(valid_exts):
                print(f"Removing: {file_path}")
                os.remove(file_path)

def normalize_name(name):
    return name.strip().lower().replace(" ", "_").replace("-", "_")

def safe_rename_class_folders(dataset_path):
    for folder in os.listdir(dataset_path):
        src_path = os.path.join(dataset_path, folder)
        if not os.path.isdir(src_path):
            continue

        normalized_name = normalize_name(folder)
        dst_path = os.path.join(dataset_path, normalized_name)

        if src_path == dst_path:
            continue  # already normalized

        if os.path.exists(dst_path):
            #merging existing paths
            for file in os.listdir(src_path):
                src_file = os.path.join(src_path, file)
                dst_file = os.path.join(dst_path, file)
                if not os.path.exists(dst_file):
                    shutil.move(src_file, os.path.join(dst_path, os.path.basename(src_file)))

            shutil.rmtree(src_path) #remove one since duplicate data

        else:
            os.rename(src_path, dst_path)

safe_rename_class_folders("/content/dataset")

clean_dataset("/content/dataset")

data_dir = "/content/dataset"  # cleaned dataset path

# Define transforms: resize, convert to tensor, normalize
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ViT and ResNet expect 224x224 images
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# Load the dataset
full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)

with open("class_names.json", "w") as f:
    json.dump(full_dataset.classes, f)

print(f"Total images: {len(full_dataset)}")
print(f"Classes found: {full_dataset.classes}")

train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size

train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

print(f"Training samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")

batch_size = 16

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

num_classes = len(full_dataset.classes)  # number of species/classes in dataset

# Load pretrained ViT base model, pretrained on ImageNet-21k
model_name = "google/vit-base-patch16-224-in21k"

model = ViTForImageClassification.from_pretrained(
    model_name,
    num_labels=num_classes,        # replace classification head
    ignore_mismatched_sizes=True,  # load pretrained weights except classification head
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

feature_extractor = ViTFeatureExtractor.from_pretrained("google/vit-base-patch16-224-in21k")

def vit_transform(image):
    # image: PIL Image
    # Returns dict with 'pixel_values' tensor ready for ViT input
    encoding = feature_extractor(images=image, return_tensors="pt")
    return encoding['pixel_values'].squeeze()  # remove batch dimension

# update your dataset transform:

dataset = ImageFolder(
    root=data_dir,
    transform=vit_transform
)

def train(model, train_dataset, val_dataset, epochs=5, batch_size=16, lr=5e-5, save_path="best_model.pth"):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.train()

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)

    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    criterion = torch.nn.CrossEntropyLoss()

    best_val_acc = 0.0

    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        running_loss = 0.0
        correct = 0
        total = 0

        loop = tqdm(train_loader, leave=True)
        for pixel_values, labels in loop:
            pixel_values = pixel_values.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            outputs = model(pixel_values)

            loss = criterion(outputs.logits, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, preds = torch.max(outputs.logits, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            loop.set_description(f"Loss: {running_loss/total:.4f} Acc: {correct/total:.4f}")

        val_acc = evaluate(model, val_loader, device)
        print(f"Validation Accuracy: {val_acc:.4f}")

        # Save checkpoint if validation accuracy improved
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), save_path)
            print(f"Best model saved with accuracy: {best_val_acc:.4f}")

def evaluate(model, dataloader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for pixel_values, labels in dataloader:
            pixel_values = pixel_values.to(device)
            labels = labels.to(device)
            outputs = model(pixel_values)
            _, preds = torch.max(outputs.logits, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    model.train()
    return correct / total

def load_model(model_class, weights_path, num_labels):
    """
    model_class: callable that returns a model instance (e.g. your ViT init code)
    weights_path: path to the saved .pth file
    num_labels: number of classes for classification head
    """
    model = model_class(num_labels=num_labels)
    model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))  # or 'cuda' if available
    model.eval()
    return model

def create_vit_model(num_labels):
    config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=num_labels)
    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', config=config)
    return model

train(model, train_dataset, val_dataset, epochs=5, batch_size=16, lr=5e-5)
model = load_model(create_vit_model, "best_model.pth", num_classes)

torch.save(model.state_dict(), "best_model.pth")

files.download("best_model.pth")

files.download("class_names.json")